{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc21e578-7bd6-4e78-ab59-520afc76d4bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PyTorch Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3ed83c-581d-4c70-a3d4-760e2b46e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea0b39-bf4e-4a7d-a596-0571ccd6cd6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Tensor Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df00efd-8731-44cf-9213-39dd9d149fcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe863cb-850d-41d1-9854-c55d4ac8bcf1",
   "metadata": {},
   "source": [
    "This is for running calculations on GPU with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4aca760-7815-4b72-aba1-ff88f9a4e23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1,2,3]) # Create a tensor\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5291d785-f70f-4aa3-9bf7-068d850cb208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.cuda() # Move the tensor to CUDA and reassign to t\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3b729d-5282-4351-bfbf-c40ba4a49a15",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9143940-58ff-453e-ad85-28fc967f3d48",
   "metadata": {},
   "source": [
    "Indexing tensors is just like indexing NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e13d88-baea-470a-99ad-270714e4cc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1,2,3])\n",
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ec8c7a-c363-4ad1-a7ab-b7b332503bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed5fe2e1-df26-446c-9324-fed82e187c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfdb2b6b-a829-4e08-8e3d-680b7700c2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea2f937-4ab7-4fd9-91d3-ba7c514e0b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31a36213-347a-4a5d-a7ef-57fb45b7f4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464acb9-09b6-497b-827d-2288144f0c22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Theoretical Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b916ee-5da5-47e9-9a41-bd297df9a7e8",
   "metadata": {},
   "source": [
    "A tensor is a multi-dimensional data structure.\n",
    "A tensor is an abstraction of all the following objects: \n",
    "1. Scalars/numbers\n",
    "2. Vectors/arrays\n",
    "3. Matrices/2D-arrays\n",
    "4. nd-arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bac1bd-ae91-475d-adee-6b6c4bb93db7",
   "metadata": {},
   "source": [
    "There are three main tensor attributes:\n",
    "1. Rank - The number of dimensions\n",
    "2. Axes - A specific dimension of the tensor (the last axis contains the numbers, all other axes contain nd-arrays)\n",
    "3. Shape - The length of each axis in the tensor in order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c380314a-6e84-4eb8-8b4a-56b03c87c52e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PyTorch Tensor Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345643a-e108-4336-a815-e31f7cd324df",
   "metadata": {},
   "source": [
    "The PyTorch tenspr object has the following attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54738173-cb6c-4ee0-8db0-c8fa5477c569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor()\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2738efbd-7bc2-458d-91f2-a74425742802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "print(t.dtype) # Data-type stored in the tensor\n",
    "print(t.device) # Device where the tensor exists\n",
    "print(t.layout) # How memory is stored internally (default is strided)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad57b50-52c0-46f5-a4a7-9dd728e56b19",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7260f402-52e1-4136-9fc0-49cae11deb23",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Without Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95f4b7fb-140b-4e41-ba08-a3d6f9ac7c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3) # Identity tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16c2f8b-a2e1-4ac6-8422-72d71142dd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,3) # Zero tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a3e9480-e288-4430-8f0f-876e4d846d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2,2) # Ones tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1080064-0b1d-4529-aad4-3c0e27b6350a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0193, 0.6596, 0.7168, 0.1136, 0.6257]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1,5) # Random tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c9d85-da98-41c3-a7e1-8ee07a256e9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### With Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85bd842f-3f4e-47d0-ac6f-0763f7f067c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb85af7-0c36-45c5-9a80-063f2b7913a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1  = torch.Tensor(data) # Constructor\n",
    "t2 = torch.tensor(data) # Factory function\n",
    "t3 = torch.as_tensor(data) # Factory function\n",
    "t4 = torch.from_numpy(data) # Factory function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a572106e-e423-4f3a-92b0-8719bc123cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(t1) # Does not preserve original dtype\n",
    "print(t2) # Preserves original dtype\n",
    "print(t3) # Preserves original dtype\n",
    "print(t4) # Preserves original dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ab61f42-f9d3-48e7-9fe8-0f52ae7fcbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a149ead6-e191-442b-8179-20a94c854afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([0, 2, 3], dtype=torch.int32)\n",
      "tensor([0, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(t1) # Does not share memory with original data\n",
    "print(t2) # Does not share memory with original data\n",
    "print(t3) # Shares memory with original data\n",
    "print(t4) # Shares memory with original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e8ccf-4d04-43b1-bce0-9775253c524f",
   "metadata": {},
   "source": [
    "#### Best Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab7e6d8a-e01d-446d-9ed6-4950e20d673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1,2,3], dtype=torch.float32) # The go-to option is to use the refactory function (and specify type if nescecery)\n",
    "t = torch.as_tensor(data) # Use as_tensor if you want to take advantage of memory sharing for performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071938c-2efb-4527-b7c3-e1fcc9de4979",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eed0189-ed96-4ed8-92c1-f1fa9e59bfcd",
   "metadata": {},
   "source": [
    "Tensor operations can be divided into 4 broad categories:\n",
    "1. Reshaping Operations\n",
    "2. Element-wise Operations\n",
    "3. Reduction Operations\n",
    "4. Access Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348d95b-fe6b-474d-9f10-9391d108f373",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reshaping Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9072d3-4406-4b69-8ad2-8fd3b4265475",
   "metadata": {},
   "source": [
    "A reshaping operation modifies the shape of a tensor, but the data is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db76702c-9394-43e7-82c7-863c3bb4628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,2,3,4],\n",
    "    [5,6,7,8],\n",
    "    [9,10,11,12],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788021d2-3534-4ca1-955f-61c531a65043",
   "metadata": {},
   "source": [
    "#### Shape Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b1484ff-c550-4f23-b5ef-d0aa6bddf26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2b97f1a-9d76-4437-988a-e3788ab0534b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size() # Same as shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51ecb35a-899a-45f4-8919-8672dec06813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t.shape) # Rank i.e number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6c11053-6785-42c4-9253-1797c8689e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numel() # Number of elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6a958-c5b2-411c-83a5-2dff8e401abb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbcc7460-f9f7-4596-bf75-95e28ae1c772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63888655-cfcf-4516-a21a-507eaa87b252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6],\n",
       "        [ 7,  8,  9, 10, 11, 12]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a8bb96f-077d-48a0-97ca-31838f2e398a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36d2c03e-bf78-4120-92b5-901508db5fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2],\n",
       "        [ 3,  4],\n",
       "        [ 5,  6],\n",
       "        [ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(6,-1) # -1 makes it infer that dimension from the number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e7bf478-01d2-4540-b816-a497e4decba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[ 7,  8,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,2,3) # 2D to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e72a5b3-d8ec-4c41-866d-d1d4da41cf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(12) # 2D to 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44f051-43e4-4297-8e25-667364edc945",
   "metadata": {},
   "source": [
    "#### Squeeze and Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e358e559-7fe3-4c50-8082-254f09c8ffc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1,2,3,4,5]).reshape(1,5)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "628432ff-8388-4631-9553-1c3b8ca4019c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.squeeze() # Removes any dimensions of length 1\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a28262fd-fe8b-4e8d-af0f-7c864b029ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.unsqueeze(axis=0) # Adds back a dimension of length 1 at position 0 in the shape\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b3a065c-93ff-4594-aa70-db7237ae1a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.unsqueeze(axis=2)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "418189dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fbe168-fe84-4a42-bfb2-ef96c5e9cb19",
   "metadata": {},
   "source": [
    "#### Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe556462-adb8-44f5-a5f4-69bdd085b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f089e60c-db17-4f92-bc17-0153d68dda70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.flatten() # Flattens the tensor into a 1D tensor of length numel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c915e76-3f92-48ae-beac-ff9e8192e3c5",
   "metadata": {},
   "source": [
    "#### Concatenation and Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5760147-0f3d-46cf-b4ab-4524ce6c7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "t2 = torch.tensor([\n",
    "    [5,6],\n",
    "    [7,8]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b14a5d1a-0a53-4623-92ef-5c07f25f955d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((t1, t2), axis=0) # Concatenates tensors along some existing axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a2ed0f9-417e-4f2e-9b64-a1facc1e32f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 6],\n",
       "        [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((t1,t2), dim=1) # Axis and dim are interchangable (almost everywhere!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e207e3b-a998-4e97-9b3d-c9b1be4e3b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((t1,t2)) # Creates a new axis to stack the tensors (tensors must all have same dimensions to begin with)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0b1e97-b632-4973-a75c-46c9c13d6297",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Element-wise Operations (with Broadcasting)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1580248-5561-479f-9bf3-93e943654a4e",
   "metadata": {},
   "source": [
    "An element-wise operation operates on corresponding elements between tensors. These only work when both the tensors are of the same type and on the same device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae5f4db2-0e36-4d46-815c-be1e49e095b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "t2 = torch.tensor([\n",
    "    [9,8],\n",
    "    [7,6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d24f782a-0966-43aa-b9c2-9dae8af85ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10, 10],\n",
       "         [10, 10]]),\n",
       " tensor([[ 9, 16],\n",
       "         [21, 24]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1+t2, t1*t2 # Arithmatic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "770f3edc-1443-4c5f-8579-9d9e62365e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-4, -3],\n",
       "         [-2, -1]]),\n",
       " tensor([[1, 0],\n",
       "         [1, 0]]),\n",
       " tensor([[2, 4],\n",
       "         [4, 6]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1-5, t2%2, t1+torch.tensor([1,2]) # Using broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "192bd503-152b-40e2-b9fd-c3831425b8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [1 2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4],\n",
       "        [4, 6]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last broadcasting explained\n",
    "print(np.broadcast_to([1,2], t1.shape))# The 1D tensor is bradcasted to a 2D tensor\n",
    "t1 + torch.tensor(np.broadcast_to([1,2], t1.shape)) # So under the hood it actually does this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a2ab2e2-9fd0-4c9b-9691-40d37674cc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ True, False],\n",
       "         [False, False]]),\n",
       " tensor([[ True,  True],\n",
       "         [ True, False]]),\n",
       " tensor([[False,  True],\n",
       "         [False,  True]]),\n",
       " tensor([[True, True],\n",
       "         [True, True]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1<2, t2>6, t1%2==0, t1<=t2 # Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "800352f6-5203-4afc-9f64-7d32ba30d1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " tensor([[1.0000, 1.4142],\n",
       "         [1.7321, 2.0000]]),\n",
       " tensor([[-1, -2],\n",
       "         [-3, -4]]),\n",
       " tensor([[0.7311, 0.8808],\n",
       "         [0.9526, 0.9820]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.abs(), t1.sqrt(), t1.neg(), t1.sigmoid() # Using functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc8561-0c54-4f7a-882f-ddaecebb2bb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reduction Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dd0242-0a7a-48a5-9665-d34c5571bb4d",
   "metadata": {},
   "source": [
    "A reduction operation on a tensor is an operation that reduces the number of elements contained within the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5d02fcc-baa6-47a8-8682-06e2bb9277e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,2,3,4],\n",
    "    [5,6,7,8],\n",
    "    [9,10,11,12],\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e2e35-ef11-457b-8529-2e003a95b343",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reduction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3af9d96a-4774-4eb3-8573-7d30fe012738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(78.), tensor(4.7900e+08), tensor(6.5000), tensor(3.6056), tensor(13.))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(), t.prod(), t.mean(), t.std(), t.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c1b4d87-2e4e-4478-8ecf-06168582e5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 26., 42.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(axis=1) # Squeezes out dimensions of length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04ac3603-f7c5-45ce-9552-88bd291a9242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [26.],\n",
       "        [42.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(axis=1, keepdim=True) # Maintains the original number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e34e6ea9-8e53-488c-a289-26a9741b72d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15., 18., 21., 24.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "393d56c0-59f5-465a-ad7e-1525634a1192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 18., 21., 24.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(axis=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babf85f-7d7c-4f37-a4a7-b61b2429fa35",
   "metadata": {},
   "source": [
    "#### Max and Argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0760302f-6963-4b62-9d88-02e7ae1a1f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86b3f2ea-4c96-48c7-944c-6cc90e73fb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.argmax() # Position of max value when flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2912b0f-088c-4332-b936-142ecbd8b8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([ 4.,  8., 12.]),\n",
       "indices=tensor([3, 3, 3]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max(axis=1) # Maximum over a specific axis (returns max values and positions within that axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ddc44d00-5412-412c-b817-dc8fb946a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f0dd71-9588-4e67-84a5-8358f88cb9e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Access Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f32ef-7a80-4e9e-b09b-914e48bc2207",
   "metadata": {},
   "source": [
    "An access operation is used to take the data in the tensor out of PyTorch for external use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5f8fd6f-8c6a-487e-8821-b690a35d258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca9de100-fe7b-4de8-a663-4330b6990c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50ca3393-b1fd-449f-aed9-0fc4edae8898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum().item() # Converts the tensor of length 1 into a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1095a4ca-f8c5-4310-a164-8bfac2b6e588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tolist() # Converts the tensor into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "091f5f22-e1e3-4135-ae83-8e31b0e7ad56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy() # Converts the tensor into a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc05733-bfb0-4175-bc68-a1ae58e847e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Building Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dafea5-72d5-471e-ae2b-b836e9714565",
   "metadata": {},
   "source": [
    "We can build networks in PyTorch by using the `torch.nn` package. There are two methods to build a network: \n",
    "1. As a class that extends `nn.Module`\n",
    "2. Using the `nn.Sequential` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e01d46a-caff-473f-a8f0-3b3c06ef0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 512\n",
    "out_features = 256\n",
    "out_classes = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8cb5fa-a1ee-4556-abac-664c0120875f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extending `nn.Module`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a582fdf9-dcfd-4c9d-87e7-a671e0a51e19",
   "metadata": {},
   "source": [
    "In PyTorch, neural networks are implemented using object oriented programming. Layers in a neural network (and even entire networks themselves) are implemented as objects that extend the ``nn.Module`` class. The transformations are done using the methods and the weights are stored as attributes within the class.\n",
    "\n",
    "Note that both individual layers and entire networks both extend the same ``nn.Module`` class since a network can be thought of as just one big layer.\n",
    "\n",
    "When we pass a tensor to our network as input, the tensor flows forward though each layer transformation until the tensor reaches the output layer. This process of a tensor flowing forward though the network is known as a forward pass.\n",
    "\n",
    "Each layer has its own transformation (specified in the code) and the tensor passes forward through each layer. The composition of all the individual layer forward passes defines the overall forward pass transformation for the network.\n",
    "\n",
    "The goal of the overall transformation is to transform or map the input to the correct prediction output class, and during the training process, the layer weights (data) are updated in such a way that cause the mapping to adjust to make the output closer to the correct prediction.\n",
    "\n",
    "What this all means is that, every PyTorch ``nn.Module`` has a ``forward()`` method, and so when we are building layers and networks, we must provide an implementation of the ``forward()`` method. The forward method is the actual transformation. When implementing the forward method, we typically use functions from the ``nn.functional`` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "90878c24-d46a-4272-8e54-2861ba91788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # PyTorch automatically keeps track of the learnable parameters in layers defined as attributes\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.fc = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        self.out = nn.Linear(in_features=out_features, out_features=out_classes)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = self.flatten(t)\n",
    "        t = self.fc(t)\n",
    "        t = self.out(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "082c5a08-833d-479e-816f-69f64e9890ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (out): Linear(in_features=256, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = Network()\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153f9e6-4099-42e8-a876-173d4e932d90",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using `nn.Sequential`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67329d27-ee9e-4863-a60a-931103371d16",
   "metadata": {},
   "source": [
    "The Sequential class allows us to build PyTorch neural networks on-the-fly without having to build an explicit class. This make it much easier to rapidly build networks and allows us to skip over the step where we implement the `forward()` method. When we use the sequential way of building a PyTorch network, we construct the `forward()` method implicitly by defining our network's architecture sequentially.\n",
    "\n",
    "A sequential module is a container or wrapper class that extends the nn.Module base class and allows us to compose modules together. We can compose any `nn.Module` with in any other ``nn.Module``.\n",
    "\n",
    "This means that we can compose layers to make networks, and since networks are also ``nn.Module`` instances, we can also compose networks with one another. Additionally, since the Sequential class is also a `nn.Module` itself, we can even compose Sequential modules with one another.\n",
    "\n",
    "At this point, we may be wondering about other required functions and operations, like pooling operations or activation functions. It turns out that all of the functions and operations in the `nn.functional` API have been wrapped up into `nn.Module` classes. This allows us to pass things like activation functions to Sequential wrappers to fully build out our networks in a sequential way. There are 3 ways to use the `nn.Sequential` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ca2e163-a498-4763-b9aa-4e3c118ba864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (2): Linear(in_features=256, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = nn.Sequential(\n",
    "    nn.Flatten(start_dim=1), # Flatten the individual images but keep batch dimension\n",
    "    nn.Linear(in_features, out_features),\n",
    "    nn.Linear(out_features, out_classes),\n",
    ")\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c412170-77ee-47fb-b0a1-d08cc1ef8027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (hidden): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = OrderedDict([\n",
    "    ('flat', nn.Flatten(start_dim=1)),\n",
    "    ('hidden', nn.Linear(in_features, out_features)),\n",
    "    ('output', nn.Linear(out_features, out_classes)),\n",
    "])\n",
    "network = nn.Sequential(layers)\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e55ca2b7-c8a7-4154-bab0-03ec153dba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (hidden): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = nn.Sequential()\n",
    "network.add_module('flat', nn.Flatten(start_dim=1))\n",
    "network.add_module('hidden', nn.Linear(in_features, out_features))\n",
    "network.add_module('output', nn.Linear(out_features, out_classes))\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8c707-55fe-46c4-957f-aa1f42fa115b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Using GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a700a1-2b74-45af-80f6-b40baad36c4c",
   "metadata": {},
   "source": [
    "Training a neural network involves a lot of computations that can be done in paralell, hence using a GPU (wherever available) can allow for dramatic decreases in training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dbbc20-4c0d-4b29-ad04-f87748c68227",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04aa9e7b-a401-41f7-9919-415a5d37aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ad660f5-a10b-43b4-8dfe-e6e24e747b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.device # Default device is cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6d6cea0-b1c0-4330-80c1-376f0ea6f777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.cuda() # Moves tensor to cuda\n",
    "t.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa8d61d4-d124-472a-8b5d-2f526d8a4d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # device is a string corresponding to the best available device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e0e3e7ec-45d4-44ee-ace1-86b09b5e7d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.to(device) # Moves the tensor to whatever is stored in the `device` string\n",
    "t.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c17d879-9158-49b4-8033-eed4b0c18bda",
   "metadata": {},
   "source": [
    "Tensor operations between tensors between tensors can only be done when both tensors are on the same device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ee2fc-7d4a-4286-a177-d0e0d67fa588",
   "metadata": {},
   "source": [
    "### Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6c32a2d6-9d24-4999-9bb0-e535f0a83828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = nn.Sequential(\n",
    "    nn.Linear(in_features=64, out_features=32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=32, out_features=16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=16, out_features=10),\n",
    ")\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df785600-b015-45a4-8e9e-f64afcf92680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight  \t  cpu  \t  torch.Size([32, 64])\n",
      "0.bias  \t  cpu  \t  torch.Size([32])\n",
      "2.weight  \t  cpu  \t  torch.Size([16, 32])\n",
      "2.bias  \t  cpu  \t  torch.Size([16])\n",
      "4.weight  \t  cpu  \t  torch.Size([10, 16])\n",
      "4.bias  \t  cpu  \t  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in network.named_parameters():\n",
    "    print(f'{name}  \\t  {param.device}  \\t  {param.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b23499ca-306c-4243-bfb9-9bc9e8780adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight  \t  cuda:0  \t  torch.Size([32, 64])\n",
      "0.bias  \t  cuda:0  \t  torch.Size([32])\n",
      "2.weight  \t  cuda:0  \t  torch.Size([16, 32])\n",
      "2.bias  \t  cuda:0  \t  torch.Size([16])\n",
      "4.weight  \t  cuda:0  \t  torch.Size([10, 16])\n",
      "4.bias  \t  cuda:0  \t  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "network.to(device) # Shifts all the parameter tensors to the device\n",
    "\n",
    "for name, param in network.named_parameters():\n",
    "    print(f'{name}  \\t  {param.device}  \\t  {param.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caace8d3-1967-434e-b5de-1402480e87cb",
   "metadata": {},
   "source": [
    "A tensor can only be passed through a network when the tensor and the parameter tensors of the network are all on the same device."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "58269206bccec84f87976bba860a8b49b0f079e4002cfd74b6f2755e01d9cc9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
